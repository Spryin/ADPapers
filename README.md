# ADPapers
List of Papers on Attack and Defense (AD) in AI Models


### Natural Language Processing
- Attack
- Defense

### Compuper Vision
- Attack
- # ADPapers
List of Papers on Attack and Defense (AD) in AI Models


### Natural Language Processing
- Attack
- Defense

### Compuper Vision
- Attack
1. **See through Gradients: Image Batch Recovery via GradInversion**. *Hongxu Yin, Arun Mallya, Arash Vahdat, Jose M. Alvarez, Jan Kautz, Pavlo Molchanov*. CVPR 2021. [[pdf](https://openaccess.thecvf.com/content/CVPR2021/papers/Yin_See_Through_Gradients_Image_Batch_Recovery_via_GradInversion_CVPR_2021_paper.pdf)]
2. **LAFEAT : Piercing Through Adversarial Defenses with Latent Features**. *Yunrui Yu, Xitong Gao, Cheng-Zhong Xu*. CVPR 2021. [[pdf](https://openaccess.thecvf.com/content/CVPR2021/papers/Yu_LAFEAT_Piercing_Through_Adversarial_Defenses_With_Latent_Features_CVPR_2021_paper.pdf)]
3. **Unlearnable Examples: Making Personal Data Unexploitable**. *Hanxun Huang, Xingjun Ma, Sarah Monazam Erfani, James Bailey, Yisen Wang*. ICLR 2021. [[pdf](https://arxiv.org/pdf/2101.04898.pdf)]
4. **Fooling Detection Alone is Not Enough: Adversarial Attack against Multiple Object Tracking**. *Yunhan Jia, Yantao Lu, Junjie Shen, Qi Alfred Chen, Zhenyu Zhong, Tao Wei*. ICLR 2020. [[pdf](https://par.nsf.gov/servlets/purl/10156929)]
5. **Sponge Examples: Energy-Latency Attacks on Neural Networks**. *Ilia Shumailov, Yiren Zhao, Daniel Bates, Nicolas Papernot, Robert Mullins, Ross Anderson*. Euro S&P 2021. [[pdf](https://arxiv.org/pdf/2006.03463.pdf)]
6. **Minimally distorted Adversarial Examples with a Fast Adaptive Boundary Attack**. *Francesco Croce, Matthias Hein*. ICML 2020. [[pdf](http://proceedings.mlr.press/v119/croce20a/croce20a.pdf)] `theory`
7. **Stronger and Faster Wasserstein Adversarial Attacks**. *Kaiwen Wu, Allen Wang, Yaoliang Yu*. ICML 2020. [[pdf](http://proceedings.mlr.press/v119/wu20d/wu20d.pdf)]  `theory`
8. **QEBA: Query-Efﬁcient Boundary-Based Blackbox Attack**. *Huichen Li, Xiaojun Xu, Xiaolu Zhang, Shuang Yang, Bo Li*. CVPR 2020. [[pdf](https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_QEBA_Query-Efficient_Boundary-Based_Blackbox_Attack_CVPR_2020_paper.pdf)]
9. **New Threats Against Object Detector with Non-local Block**. *Yi Huang, Fan Wang, Adams Wai-Kin Kong, Kwok-Yan Lam*. ECCV 2020. [[pdf](https://link.springer.com/content/pdf/10.1007%2F978-3-030-58565-5_29.pdf)]
10. **Frequency-Tuned Universal Adversarial Attacks**. *Yingpeng Deng, Lina J. Karam*. ECCV 2020. [[pdf](https://arxiv.org/pdf/2003.05549.pdf)]
11. **Learning Transferable Adversarial Examples via Ghost Networks**. *Yingwei Li, Song Bai, Yuyin Zhou, Cihang Xie, Zhishuai Zhang, Alan Yuille*. [[pdf](https://www.cs.jhu.edu/~alanlab/Pubs19/li2019learning.pdf)]
12. **SPARK: Spatial-aware Online Incremental Attack Against Visual Tracking**. *Qing Guo, Xiaofei Xie, Felix Juefei-Xu, Lei Ma, Zhongguo Li, Wanli Xue, Wei Feng, Yang Liu*. ECCV 2020. [[pdf](https://link.springer.com/content/pdf/10.1007/978-3-030-58595-2_13.pdf)]
13. **Inverting Gradients - How easy is it to break privacy in federated learning?**. *Jonas Geiping, Hartmut Bauermeister, Hannah Dröge, Michael Moeller*. Neurips 2020. [[pdf](https://proceedings.neurips.cc/paper/2020/file/c4ede56bbd98819ae6112b20ac6bf145-Paper.pdf)]
14. **Nesterov Accelerated Gradient and Scale Invariance for Adversarial Attacks**. *Jiadong Lin, Chuanbiao Song, Kun He, Liwei Wang, John E. Hopcroft*. ICLR 2020. [[pdf](https://proceedings.neurips.cc/paper/2020/file/c4ede56bbd98819ae6112b20ac6bf145-Paper.pdf)]
15. **SemanticAdv: Generating Adversarial Examples via Attribute-conditional Image Editing**. *Haonan Qiu, Chaowei Xiao, Lei Yang, Xinchen Yan, Honglak Lee, Bo Li*. ECCV 2020. [[pdf](https://link.springer.com/content/pdf/10.1007%2F978-3-030-58568-6_2.pdf)]
16. **Feature Space Perturbations Yield More Transferable Adversarial Examples**. *Nathan Inkawhich, Wei Wen, Hai (Helen) Li, Yiran Chen*. CVPR 2019. [[pdf](https://openaccess.thecvf.com/content_CVPR_2019/papers/Inkawhich_Feature_Space_Perturbations_Yield_More_Transferable_Adversarial_Examples_CVPR_2019_paper.pdf)]
17. **The Limitations of Adversarial Training and the Blind-Spot Attack**. *Huan Zhang, Hongge Chen, Zhao Song, Duane Boning, Inderjit S. Dhillon, Cho-Jui Hsieh*. ICLR 2019. [[pdf](https://arxiv.org/pdf/1901.04684.pdf)]
18. **Are adversarial examples inevitable?** *Ali Shafahi, W. Ronny Huang, Christoph Studer, Soheil Feizi, Tom Goldstein*. ICLR 2019. [[pdf](https://arxiv.org/pdf/1809.02104.pdf)]
19. **One pixel attack for fooling deep neural networks**. *Jiawei Su, Danilo Vasconcellos Vargas, Kouichi Sakurai*. IEEE TEC 2019. [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8601309)]
20. **NATTACK: Learning the Distributions of Adversarial Examples for an Improved Black-Box Attack on Deep Neural Networks**. *Yandong Li, Lijun Li, Liqiang Wang, Tong Zhang, Boqing Gong*. ICML 2019. [[pdf](http://proceedings.mlr.press/v97/li19g/li19g.pdf)]
- Defense

### Speech
- Attack
- Defense

- Defense

### Speech
- Attack
- Defense
