# ADPapers
List of Papers on Attack and Defense (AD) in AI Models


### Natural Language Processing
- Attack
- Defense

### Computer Vision
- Attack
1. **See through Gradients: Image Batch Recovery via GradInversion**. *Hongxu Yin, Arun Mallya, Arash Vahdat, Jose M. Alvarez, Jan Kautz, Pavlo Molchanov*. CVPR 2021. [[pdf](https://openaccess.thecvf.com/content/CVPR2021/papers/Yin_See_Through_Gradients_Image_Batch_Recovery_via_GradInversion_CVPR_2021_paper.pdf)]
2. **LAFEAT : Piercing Through Adversarial Defenses with Latent Features**. *Yunrui Yu, Xitong Gao, Cheng-Zhong Xu*. CVPR 2021. [[pdf](https://openaccess.thecvf.com/content/CVPR2021/papers/Yu_LAFEAT_Piercing_Through_Adversarial_Defenses_With_Latent_Features_CVPR_2021_paper.pdf)]
3. **Unlearnable Examples: Making Personal Data Unexploitable**. *Hanxun Huang, Xingjun Ma, Sarah Monazam Erfani, James Bailey, Yisen Wang*. ICLR 2021. [[pdf](https://arxiv.org/pdf/2101.04898.pdf)]
4. **Towards Universal Physical Attacks on Single Object Tracking**. *Li Ding, Yongwei Wang, Kaiwen Yuan, Minyang Jiang, Ping Wang, Hua Huang, Z. Jane Wang*. AAAI 2021. [[pdf](https://www.aaai.org/AAAI21Papers/AAAI-2606.DingL.pdf)]
5.  **Attack to Fool and Explain Deep Networks**. *Naveed Akhtar, Mohammad A. A. K. Jalwana, Mohammed Bennamoun, and Ajmal Mian*.TPAMI 2021. [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9442299)]
6. **Fooling Detection Alone is Not Enough: Adversarial Attack against Multiple Object Tracking**. *Yunhan Jia, Yantao Lu, Junjie Shen, Qi Alfred Chen, Zhenyu Zhong, Tao Wei*. ICLR 2020. [[pdf](https://par.nsf.gov/servlets/purl/10156929)]
7. **Sponge Examples: Energy-Latency Attacks on Neural Networks**. *Ilia Shumailov, Yiren Zhao, Daniel Bates, Nicolas Papernot, Robert Mullins, Ross Anderson*. Euro S&P 2021. [[pdf](https://arxiv.org/pdf/2006.03463.pdf)]
8. **Minimally distorted Adversarial Examples with a Fast Adaptive Boundary Attack**. *Francesco Croce, Matthias Hein*. ICML 2020. [[pdf](http://proceedings.mlr.press/v119/croce20a/croce20a.pdf)] `theory`
9. **Stronger and Faster Wasserstein Adversarial Attacks**. *Kaiwen Wu, Allen Wang, Yaoliang Yu*. ICML 2020. [[pdf](http://proceedings.mlr.press/v119/wu20d/wu20d.pdf)]  `theory`
10. **QEBA: Query-Efﬁcient Boundary-Based Blackbox Attack**. *Huichen Li, Xiaojun Xu, Xiaolu Zhang, Shuang Yang, Bo Li*. CVPR 2020. [[pdf](https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_QEBA_Query-Efficient_Boundary-Based_Blackbox_Attack_CVPR_2020_paper.pdf)]
11. **New Threats Against Object Detector with Non-local Block**. *Yi Huang, Fan Wang, Adams Wai-Kin Kong, Kwok-Yan Lam*. ECCV 2020. [[pdf](https://link.springer.com/content/pdf/10.1007%2F978-3-030-58565-5_29.pdf)]
12. **Frequency-Tuned Universal Adversarial Attacks**. *Yingpeng Deng, Lina J. Karam*. ECCV 2020. [[pdf](https://arxiv.org/pdf/2003.05549.pdf)]
13. **Learning Transferable Adversarial Examples via Ghost Networks**. *Yingwei Li, Song Bai, Yuyin Zhou, Cihang Xie, Zhishuai Zhang, Alan Yuille*. [[pdf](https://www.cs.jhu.edu/~alanlab/Pubs19/li2019learning.pdf)]
14. **SPARK: Spatial-aware Online Incremental Attack Against Visual Tracking**. *Qing Guo, Xiaofei Xie, Felix Juefei-Xu, Lei Ma, Zhongguo Li, Wanli Xue, Wei Feng, Yang Liu*. ECCV 2020. [[pdf](https://link.springer.com/content/pdf/10.1007/978-3-030-58595-2_13.pdf)]
15. **Inverting Gradients - How easy is it to break privacy in federated learning?**. *Jonas Geiping, Hartmut Bauermeister, Hannah Dröge, Michael Moeller*. Neurips 2020. [[pdf](https://proceedings.neurips.cc/paper/2020/file/c4ede56bbd98819ae6112b20ac6bf145-Paper.pdf)]
16. **Nesterov Accelerated Gradient and Scale Invariance for Adversarial Attacks**. *Jiadong Lin, Chuanbiao Song, Kun He, Liwei Wang, John E. Hopcroft*. ICLR 2020. [[pdf](https://proceedings.neurips.cc/paper/2020/file/c4ede56bbd98819ae6112b20ac6bf145-Paper.pdf)]
17. **SemanticAdv: Generating Adversarial Examples via Attribute-conditional Image Editing**. *Haonan Qiu, Chaowei Xiao, Lei Yang, Xinchen Yan, Honglak Lee, Bo Li*. ECCV 2020. [[pdf](https://link.springer.com/content/pdf/10.1007%2F978-3-030-58568-6_2.pdf)]
18. **Adversarial Attack on Deepfake Detection Using RL Based Texture Patches**. *Steven Lawrence Fernandes, Sumit Kumar Jha*. ECCV 2020. [[pdf](https://link.springer.com/content/pdf/10.1007%2F978-3-030-66415-2_14.pdf)] `video`
19. **One-Shot Adversarial Attacks on Visual Tracking With Dual Attention**. *Xuesong Chen, Xiyu Yan, Feng Zheng, Yong Jiang, Shu-Tao Xia, Yong Zhao, Rongrong Ji*. CVPR 2020. [[pdf](https://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_One-Shot_Adversarial_Attacks_on_Visual_Tracking_With_Dual_Attention_CVPR_2020_paper.pdf)]
20. **Backpropagating Linearly Improves Transferability of Adversarial Examples**. *Yiwen Guo, Qizhang Li, Hao Chen*. NeurIPS 2020. [[pdf](https://arxiv.org/pdf/2012.03528.pdf)]
21. **Yet Another Intermediate-Level Attack**. *Qizhang Li, Yiwen Guo, Hao Chen*. ECCV 2020. [[pdf](https://link.springer.com/content/pdf/10.1007%2F978-3-030-58517-4_15.pdf)]
22. **Practical No-box Adversarial Attacks against DNNs**. *Qizhang Li, Yiwen Guo, Hao Chen*. NeurIPS 2020. [[pdf](https://arxiv.org/pdf/2012.02525.pdf)]
23. **Adversarial Attack on Deep Learning-Based Splice Localization**. *Andras Rozsa, Zheng Zhong, Terrance E. Boult*. CVPRW 2020. [[pdf](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w39/Rozsa_Adversarial_Attack_on_Deep_Learning-Based_Splice_Localization_CVPRW_2020_paper.pdf)]
24. ****. **. iiii 2019. [[pdf]()]
25. **Perturbing Across the Feature Hierarchy to Improve Standard and Strict Blackbox Attack Transferability**. *Nathan Inkawhich, Kevin Liang, Binghui Wang, Matthew Inkawhich, Lawrence Carin, Yiran Chen*. NeurIPS 2020. [[pdf](https://arxiv.org/pdf/2004.14861.pdf)]
26. **Feature Space Perturbations Yield More Transferable Adversarial Examples**. *Nathan Inkawhich, Wei Wen, Hai (Helen) Li, Yiran Chen*. CVPR 2019. [[pdf](https://openaccess.thecvf.com/content_CVPR_2019/papers/Inkawhich_Feature_Space_Perturbations_Yield_More_Transferable_Adversarial_Examples_CVPR_2019_paper.pdf)]
27. **The Limitations of Adversarial Training and the Blind-Spot Attack**. *Huan Zhang, Hongge Chen, Zhao Song, Duane Boning, Inderjit S. Dhillon, Cho-Jui Hsieh*. ICLR 2019. [[pdf](https://arxiv.org/pdf/1901.04684.pdf)]
28. **Are adversarial examples inevitable?** *Ali Shafahi, W. Ronny Huang, Christoph Studer, Soheil Feizi, Tom Goldstein*. ICLR 2019. [[pdf](https://arxiv.org/pdf/1809.02104.pdf)]
29. **One pixel attack for fooling deep neural networks**. *Jiawei Su, Danilo Vasconcellos Vargas, Kouichi Sakurai*. IEEE TEC 2019. [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8601309)]
30. **NATTACK: Learning the Distributions of Adversarial Examples for an Improved Black-Box Attack on Deep Neural Networks**. *Yandong Li, Lijun Li, Liqiang Wang, Tong Zhang, Boqing Gong*. ICML 2019. [[pdf](http://proceedings.mlr.press/v97/li19g/li19g.pdf)]
31. **Rob-GAN: Generator, Discriminator, and Adversarial Attacker**. *Xuanqing Liu, Cho-Jui Hsieh*. CVPR 2019. [[pdf](https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_Rob-GAN_Generator_Discriminator_and_Adversarial_Attacker_CVPR_2019_paper.pdf)]
32. **Sparse and Imperceivable Adversarial Attacks**. *Francesco Croce, Matthias Hein*. ICCV 2019.[[pdf](https://openaccess.thecvf.com/content_ICCV_2019/papers/Croce_Sparse_and_Imperceivable_Adversarial_Attacks_ICCV_2019_paper.pdf)]
33. **Transferable Adversarial Attacks for Image and Video Object Detection**. *Xingxing Wei, Siyuan Liang, Ning Chen, Xiaochun Cao*. IJCAI 2019. [[pdf](https://arxiv.org/pdf/1811.12641.pdf)]
34. **Generalizable Data-Free Objective for Crafting Universal Adversarial Perturbations**. *Konda Reddy Mopuri, Aditya Ganeshan, R. Venkatesh Babu*. TPAMI 2019. [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8423654)]
35. **Decoupling Direction and Norm for Efficient Gradient-Based L2 Adversarial Attacks and Defenses**. *Jerome Rony, Luiz G. Hafemann, Luiz S. Oliveira, Ismail Ben Ayed, Robert Sabourin, Eric Granger*. CVPR 2019. [[pdf](https://openaccess.thecvf.com/content_CVPR_2019/papers/Rony_Decoupling_Direction_and_Norm_for_Efficient_Gradient-Based_L2_Adversarial_Attacks_CVPR_2019_paper.pdf)]
36. **FDA: Feature Disruptive Attack**. *Aditya Ganeshan, Vivek B.S., R. Venkatesh Babu*. ICCV 2019. [[pdf](https://openaccess.thecvf.com/content_ICCV_2019/papers/Ganeshan_FDA_Feature_Disruptive_Attack_ICCV_2019_paper.pdf)]
37. **SparseFool: a few pixels make a big difference**. *Apostolos Modas, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard*. CVPR 2019. [[pdf](https://openaccess.thecvf.com/content_CVPR_2019/papers/Modas_SparseFool_A_Few_Pixels_Make_a_Big_Difference_CVPR_2019_paper.pdf)]
38. **Adversarial Attacks on Graph Neural Networks via Meta Learning**. *Daniel Zügner, Stephan Günnemann*. ICLR 2019. [[pdf](https://arxiv.org/pdf/1902.08412.pdf)]
39. **Universal Perturbation Attack Against Image Retrieval**. *Jie Li, Rongrong Ji, Hong Liu, Xiaopeng Hong, Yue Gao, Qi Tian*. ICCV 2019. [[pdf](https://openaccess.thecvf.com/content_ICCV_2019/papers/Li_Universal_Perturbation_Attack_Against_Image_Retrieval_ICCV_2019_paper.pdf)]
40. **Enhancing Adversarial Example Transferability with an Intermediate Level Attack**. *Qian Huang, Isay Katsman, Horace He, Zeqi Gu, Serge Belongie, Ser-Nam Lim*. ICCV 2019. [[pdf](https://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_Enhancing_Adversarial_Example_Transferability_With_an_Intermediate_Level_Attack_ICCV_2019_paper.pdf)]
41. **Evading Defenses to Transferable Adversarial Examples by Translation-Invariant Attacks**. *Yinpeng Dong, Tianyu Pang, Hang Su, Jun Zhu*. CVPR 2019. [[pdf](https://openaccess.thecvf.com/content_CVPR_2019/papers/Dong_Evading_Defenses_to_Transferable_Adversarial_Examples_by_Translation-Invariant_Attacks_CVPR_2019_paper.pdf)]
42. **ADef: an Iterative Algorithm to Construct Adversarial Deformations**. *Rima Alaifari, Giovanni S. Alberti, Tandri Gauksson*. ICLR 2019. [[pdf](https://arxiv.org/pdf/1804.07729.pdf)]
43. **iDLG: Improved deep leakage from gradients**. **. NeurIPS 2019. [[pdf]()]
44. **Deep Leakage from Gradients**. *Ligeng Zhu, Zhijian Liu, Song Han*. NeurIPS 2019. [[pdf](https://proceedings.neurips.cc/paper/2019/file/60a6c4002cc7b29142def8871531281a-Paper.pdf)]
45. ****. **. iiii 2019. [[pdf]()]
46. ****. **. iiii 2019. [[pdf]()]
47. ****. **. iiii 2019. [[pdf]()]
48. ****. **. iiii 2019. [[pdf]()]
49. ****. **. iiii 2019. [[pdf]()]
50. ****. **. iiii 2019. [[pdf]()]
```
```
- Defense
1. **Improving Gradient Regularization using Complex-Valued Neural Networks**. *Eric C Yeats, Yiran Chen, Hai Li*. ICML 2021. [[pdf](http://proceedings.mlr.press/v139/yeats21a/yeats21a.pdf)]
2. **Interpreting and improving adversarial robustness of deep neural networks with neuron sensitivity**. *Chongzhi Zhang , Aishan Liu, , Xianglong Liu, Yitao Xu, Hang Yu , Yuqing Ma, and Tianlin Li*. IEEE TIP 2021. [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9286885)]
3. **Beating Attackers At Their Own Games: Adversarial Example Detection Using Adversarial Gradient Directions**. *Yuhang Wu, Sunpreet S. Arora, Yanhong Wu, Hao Yang*. AAAI 2021. [[pdf](https://arxiv.org/pdf/2012.15386.pdf)]
4. **Interpretability is a Kind of Safety: An Interpreter-based Ensemble for Adversary Defense**. *Jingyuan Wang, Yufan Wu,  Mingxuan Li, Xin Lin, Junjie Wu, Chao Li*. KDD 2020. [[pdf](https://dl.acm.org/doi/pdf/10.1145/3394486.3403044)]
5. **Probing for Artifacts: Detecting Imagenet Model Evasions**. *Jeremiah Rounds, Addie Kingsland, Michael J. Henry, Kayla R. Duskin*. CVPRW 2020. [[pdf](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w47/Rounds_Probing_for_Artifacts_Detecting_Imagenet_Model_Evasions_CVPRW_2020_paper.pdf)]
6. 
7. **One Man's Trash Is Another Man's Treasure: Resisting Adversarial Examples by Adversarial Examples**. *Chang Xiao, Changxi Zheng*. CVPR 2020. [[pdf](https://openaccess.thecvf.com/content_CVPR_2020/papers/Xiao_One_Mans_Trash_Is_Another_Mans_Treasure_Resisting_Adversarial_Examples_CVPR_2020_paper.pdf)]
8. ****. **. iiii 2019. [[pdf]()]
9. ****. **. iiii 2019. [[pdf]()]
10. **A New Defense Against Adversarial Images: Turning a Weakness into a Strength**. *Shengyuan Hu, Tao Yu, Chuan Guo, Wei-Lun Chao, Kilian Q. Weinberger*. NeurIPS 2019. [[pdf](https://arxiv.org/pdf/1910.07629.pdf)]
11. ****. **. iiii 2019. [[pdf]()]
12. 

### Speech
- Attack
- Defense
